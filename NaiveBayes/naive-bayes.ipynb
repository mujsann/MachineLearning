{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-24T15:29:19.275084Z","iopub.execute_input":"2021-07-24T15:29:19.275691Z","iopub.status.idle":"2021-07-24T15:29:19.281615Z","shell.execute_reply.started":"2021-07-24T15:29:19.275641Z","shell.execute_reply":"2021-07-24T15:29:19.280685Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def fit(X_train , Y_train):\n    result = {}\n    result['total_data'] = len(Y_train)\n    class_values = set(Y_train)\n    for current_class in class_values:\n        result[current_class] = {}\n        current_class_rows = (Y_train == current_class)\n        X_train_current = X_train[current_class_rows]\n        Y_train_current = Y_train[current_class_rows]\n        result[current_class]['total_count'] = len(Y_train_current) \n        for j in range(X_train.shape[1]):\n            result[current_class][j] = {}\n            all_possible_values = set(X_train[:,j])\n            for current_value in all_possible_values:\n                result[current_class][j][current_value] = (X_train_current[:,j] == current_value).sum()\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.282918Z","iopub.execute_input":"2021-07-24T15:29:19.283415Z","iopub.status.idle":"2021-07-24T15:29:19.299369Z","shell.execute_reply.started":"2021-07-24T15:29:19.283376Z","shell.execute_reply":"2021-07-24T15:29:19.298316Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Using logarithmic probability\ndef probability(dictionary , x , current_class):\n    output = np.log(dictionary[current_class]['total_count']) / np.log(dictionary['total_data'])\n    num_features = x.shape[-1]\n    for j in range(num_features):\n        xj = x[j]\n        count_current_class_with_value_xj = dictionary[current_class][j][xj] + 1\n        count_current_class = dictionary[current_class]['total_count'] + len(dictionary[current_class][j].keys())\n        current_xj_probability = np.log(count_current_class_with_value_xj) / np.log(count_current_class)\n        output = output + current_xj_probability\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.301660Z","iopub.execute_input":"2021-07-24T15:29:19.301996Z","iopub.status.idle":"2021-07-24T15:29:19.316680Z","shell.execute_reply.started":"2021-07-24T15:29:19.301966Z","shell.execute_reply":"2021-07-24T15:29:19.315411Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def predictSinglePoint(dictionary , x):\n    classes = dictionary.keys()\n    best_p = -1000\n    best_class = -1\n    first_run = True\n    for current_class in classes:\n        if (current_class == 'total_data'):\n            continue\n        p_current_class = probability(dictionary , x , current_class)\n        if(first_run or p_current_class > best_p):\n            best_p = p_current_class\n            best_class = current_class\n        first_run = False\n    return best_class","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.318895Z","iopub.execute_input":"2021-07-24T15:29:19.319434Z","iopub.status.idle":"2021-07-24T15:29:19.329440Z","shell.execute_reply.started":"2021-07-24T15:29:19.319383Z","shell.execute_reply":"2021-07-24T15:29:19.328268Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def predict(dictionary , X_test):\n    Y_pred = []\n    for x in X_test:\n        x_class = predictSinglePoint(dictionary , x)\n        Y_pred.append(x_class)\n    return Y_pred","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.331019Z","iopub.execute_input":"2021-07-24T15:29:19.331538Z","iopub.status.idle":"2021-07-24T15:29:19.342240Z","shell.execute_reply.started":"2021-07-24T15:29:19.331495Z","shell.execute_reply":"2021-07-24T15:29:19.341421Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\ndef makeLabelled(column):\n    second_limit = column.mean()\n    first_limit = second_limit * 0.5\n    third_limit = second_limit * 1.5\n    for i in range(0,len(column)):\n        if(column[i] < first_limit):\n            column[i] = 0\n        elif(column[i] > first_limit and column[i] < second_limit):\n            column[i] = 1\n        elif(column[i] > second_limit  and column[i] < third_limit):\n            column[i] = 2\n        else:\n            column[i] = 3\n    return column","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.343694Z","iopub.execute_input":"2021-07-24T15:29:19.344292Z","iopub.status.idle":"2021-07-24T15:29:19.356221Z","shell.execute_reply.started":"2021-07-24T15:29:19.344246Z","shell.execute_reply":"2021-07-24T15:29:19.355360Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#Import Scikit-learn\nfrom sklearn import naive_bayes\nfrom sklearn.metrics import classification_report , confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\niris = datasets.load_iris()\nX = iris.data\nY = iris.target\nfor i in range(0 , X.shape[1]):\n    X[: , i] = makeLabelled(X[: , i])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.357580Z","iopub.execute_input":"2021-07-24T15:29:19.358184Z","iopub.status.idle":"2021-07-24T15:29:19.380212Z","shell.execute_reply.started":"2021-07-24T15:29:19.358123Z","shell.execute_reply":"2021-07-24T15:29:19.379371Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"X_train , X_test , Y_train , Y_test = train_test_split(X , Y , random_state = 0 , test_size = 0.25)\ndictionary = fit(X_train , Y_train)\nY_pred = predict(dictionary , X_test)\nmatrix = confusion_matrix(Y_test , Y_pred)\nreport = classification_report(Y_test , Y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.383596Z","iopub.execute_input":"2021-07-24T15:29:19.384189Z","iopub.status.idle":"2021-07-24T15:29:19.405717Z","shell.execute_reply.started":"2021-07-24T15:29:19.384128Z","shell.execute_reply":"2021-07-24T15:29:19.404806Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(matrix)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.409567Z","iopub.execute_input":"2021-07-24T15:29:19.411305Z","iopub.status.idle":"2021-07-24T15:29:19.418211Z","shell.execute_reply.started":"2021-07-24T15:29:19.411268Z","shell.execute_reply":"2021-07-24T15:29:19.417052Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[[13  0  0]\n [ 0 16  0]\n [ 0  1  8]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        13\n           1       0.94      1.00      0.97        16\n           2       1.00      0.89      0.94         9\n\n    accuracy                           0.97        38\n   macro avg       0.98      0.96      0.97        38\nweighted avg       0.98      0.97      0.97        38\n\n","output_type":"stream"}]},{"cell_type":"code","source":"alg1 = naive_bayes.GaussianNB()\nalg1.fit(X_train , Y_train)\nY_pred = alg1.predict(X_test)\nprint(confusion_matrix(Y_test , Y_pred))\nprint(classification_report(Y_test , Y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.419516Z","iopub.execute_input":"2021-07-24T15:29:19.419859Z","iopub.status.idle":"2021-07-24T15:29:19.438672Z","shell.execute_reply.started":"2021-07-24T15:29:19.419830Z","shell.execute_reply":"2021-07-24T15:29:19.437543Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[[11  2  0]\n [ 0 16  0]\n [ 0  3  6]]\n              precision    recall  f1-score   support\n\n           0       1.00      0.85      0.92        13\n           1       0.76      1.00      0.86        16\n           2       1.00      0.67      0.80         9\n\n    accuracy                           0.87        38\n   macro avg       0.92      0.84      0.86        38\nweighted avg       0.90      0.87      0.87        38\n\n","output_type":"stream"}]},{"cell_type":"code","source":"alg2 = naive_bayes.BernoulliNB()\nalg2.fit(X_train , Y_train)\nY_pred = alg2.predict(X_test)\nprint(confusion_matrix(Y_test , Y_pred))\nprint(classification_report(Y_test , Y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.440118Z","iopub.execute_input":"2021-07-24T15:29:19.440469Z","iopub.status.idle":"2021-07-24T15:29:19.461260Z","shell.execute_reply.started":"2021-07-24T15:29:19.440439Z","shell.execute_reply":"2021-07-24T15:29:19.460138Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[[11  0  2]\n [ 0  0 16]\n [ 0  0  9]]\n              precision    recall  f1-score   support\n\n           0       1.00      0.85      0.92        13\n           1       0.00      0.00      0.00        16\n           2       0.33      1.00      0.50         9\n\n    accuracy                           0.53        38\n   macro avg       0.44      0.62      0.47        38\nweighted avg       0.42      0.53      0.43        38\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn import naive_bayes\nalg3 = naive_bayes.MultinomialNB()\nalg3.fit(X_train , Y_train)\nY_pred = alg3.predict(X_test)\nprint(confusion_matrix(Y_test , Y_pred))\nprint(classification_report(Y_test , Y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:29:19.462617Z","iopub.execute_input":"2021-07-24T15:29:19.462965Z","iopub.status.idle":"2021-07-24T15:29:19.476875Z","shell.execute_reply.started":"2021-07-24T15:29:19.462935Z","shell.execute_reply":"2021-07-24T15:29:19.475914Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"[[11  2  0]\n [ 0  0 16]\n [ 0  0  9]]\n              precision    recall  f1-score   support\n\n           0       1.00      0.85      0.92        13\n           1       0.00      0.00      0.00        16\n           2       0.36      1.00      0.53         9\n\n    accuracy                           0.53        38\n   macro avg       0.45      0.62      0.48        38\nweighted avg       0.43      0.53      0.44        38\n\n","output_type":"stream"}]}]}